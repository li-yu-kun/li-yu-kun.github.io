<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <title>
        
          [Hadoop]24 Hadoop离线项目之数据清洗 - 李玉坤 | Blog
        
    </title>

    <link rel="canonical" href="https://li-yu-kun.github.io/article/[Hadoop]24 Hadoop离线项目之数据清洗/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS --> 
    <link rel="stylesheet" href="/css/beantech.min.css">

    <link rel="stylesheet" href="/css/donate.css">
    
    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css">

    <link rel="stylesheet" href="/css/widget.css">

    <link rel="stylesheet" href="/css/rocket.css">

    <link rel="stylesheet" href="/css/signature.css">

    <link rel="stylesheet" href="/css/toc.css">

    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            background-image: url('/img/article_header/article_header.png')
            /*post*/
        
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#Hadoop" title="Hadoop">Hadoop</a>
                            
                        </div>
                        <h1>[Hadoop]24 Hadoop离线项目之数据清洗</h1>
                        <h2 class="subheading">企业级大数据应用分类、基于Maven构建大数据开发项目、手动造数据、IDEA创建maven项目、Hive完成最基本的统计分析</h2>
                        <span class="meta">
                            Posted by 李玉坤 on
                            2018-04-26
                        </span>
                    </div>
                


                </div>
            </div>
        </div>
    </div>
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">李玉坤</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Modify by Yu-Hsuan Yen -->

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <p>企业级大数据项目开发流程</p>
<pre><code>项目调研：技术？业务？【对业务很了解】  
        产品经理、非常熟悉业务、项目经理

需求分析：明确做什么 做成什么样子的（做东西不要局限于某个技术）  
        用户提出来的：显示【实现较为简单】  
        隐式的需要自己来实现

方案设计  
       概念设计（模块，模块中有哪些功能点）【国内一般都是后补详细设计也就是设计文档】  
       详细设计（具体到所有功能的实现，本套系统用哪些技术来搞定，每个功能点涉及到哪些表哪些模块，表的字段方法名接口等都要定义好）  
       系统设计（能否扩展，能否容错，可不可以定制化，监控告警等等都是这里的）

功能开发【文档代码化】  
       开发：代码层次  
       测试【本地环境】：单元测试    CICD【自动测试所有的单元测试，测试没问题后才可以上线】 

测试【测试人员的测试】（测试环境）  
       功能  
       联调【设计到很多团队的调试】  
       性能【压力测试，特别是大数据这种，需要调整一些性能资源】  
       用户【用户测试为试用，主要是用户的体验】

部署上线  
       试运行【新的和老的系统都在跑，比如新老一块跑两个月，比较两者的稳定性和差异】  
       正式上线 【灰度  一般一年或者一年半（会可能用到容器docker之类，开箱即用的；比如需要用到一些相同环境的机器）】

后期  
       还有项目二期，三期，四期，运维保障，功能开发，bug修改【也就是按照之前都流程都走了一遍】</code></pre><h1 id="企业级大数据应用分类"><a href="#企业级大数据应用分类" class="headerlink" title="企业级大数据应用分类"></a>企业级大数据应用分类</h1><pre><code>数据分析  
       自研【自己研发的一个平台，基本都是基于开源框架进行二次开发】  
       商业【】

搜索/爬虫 elk hbase soler luncen

机器学习/深度学习 【数据平台基本都有】

人工智能

离线：批处理

实时：流处理</code></pre><h1 id="基于Maven构建大数据开发项目"><a href="#基于Maven构建大数据开发项目" class="headerlink" title="基于Maven构建大数据开发项目"></a>基于Maven构建大数据开发项目</h1><h2 id="手动造数据"><a href="#手动造数据" class="headerlink" title="手动造数据"></a>手动造数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">search_engine = [</span><br><span class="line">	<span class="string">"baidu"</span>,</span><br><span class="line">	<span class="string">"google"</span>,</span><br><span class="line">	<span class="string">"biying"</span>,</span><br><span class="line">	<span class="string">"sougou"</span>,</span><br><span class="line">	<span class="string">"360"</span>,</span><br><span class="line">	<span class="string">"xunlei"</span>,</span><br><span class="line">	<span class="string">"yahu"</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">ip_slices = [<span class="number">132</span>,<span class="number">156</span>,<span class="number">124</span>,<span class="number">10</span>,<span class="number">29</span>,<span class="number">167</span>,<span class="number">143</span>,<span class="number">187</span>,<span class="number">30</span>,<span class="number">46</span>,<span class="number">55</span>,<span class="number">63</span>,<span class="number">72</span>,<span class="number">87</span>,<span class="number">98</span>,<span class="number">168</span>]</span><br><span class="line"></span><br><span class="line">http_referers = [</span><br><span class="line">	<span class="string">"http://www.baidu.com/s?wd=&#123;query&#125;"</span>,</span><br><span class="line">	<span class="string">"https://www.sogou.com/web?query=&#123;query&#125;"</span>,</span><br><span class="line">	<span class="string">"http://cn.bing.com/search?q=&#123;query&#125;"</span>,</span><br><span class="line">	<span class="string">"https://search.yahoo.com/search?p=&#123;query&#125;"</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">country = [</span><br><span class="line">	<span class="string">"CN"</span>,</span><br><span class="line">	<span class="string">"CO"</span>,</span><br><span class="line">	<span class="string">"CH"</span>,</span><br><span class="line">	<span class="string">"AE"</span>,</span><br><span class="line">	<span class="string">"US"</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">level = [<span class="string">"E"</span>,<span class="string">"W"</span>,<span class="string">"I"</span>,<span class="string">"D"</span>]</span><br><span class="line"></span><br><span class="line">domain_name = [</span><br><span class="line">	<span class="string">"v2.go2yd.com"</span>,</span><br><span class="line">	<span class="string">"sdf.dslkj.com"</span>,</span><br><span class="line">	<span class="string">"wert.liyu.com"</span>,</span><br><span class="line">	<span class="string">"wangwu.liujia.com"</span>,</span><br><span class="line">	<span class="string">"shabi.com"</span>,</span><br><span class="line">	<span class="string">"uouo.ojp.com"</span>	</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">http_referers = [</span><br><span class="line">	<span class="string">"http://v1.go2yd.com/user_upload/&#123;keyword&#125;"</span>,</span><br><span class="line">	<span class="string">"http://sdf.dslkj.com/user_selct/&#123;keyword&#125;"</span>,</span><br><span class="line">	<span class="string">"http://wert.liyu.com/user_test/&#123;keyword&#125;"</span>,</span><br><span class="line">	<span class="string">"http://wangwu.liujia.com/user_upload/&#123;keyword&#125;"</span>,</span><br><span class="line">	<span class="string">"http://shabi.com/user_de/&#123;keyword&#125;"</span>,</span><br><span class="line">	<span class="string">"http://uouo.ojp.com/user_upload/&#123;keyword&#125;"</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">keyword_mp4 = [</span><br><span class="line">	<span class="string">"1531633977627104fdecdc68fe7a2c4b96b2226fd3f4c.mp4_bd.mp4"</span>,</span><br><span class="line">	<span class="string">"6244563542345265dfbssb54gr3d4h5v54h4355xg4g4f.mp4_db.mp4"</span>,</span><br><span class="line">	<span class="string">"4562342652345345bsdbds64gf3h6f4x95g5643ft3t8k.mid"</span>,</span><br><span class="line">	<span class="string">"2656345557534787rthwjj78rf4g6fe4frt5rf44f5tg4f5tf.www4"</span>,</span><br><span class="line">	<span class="string">"8969576565675647fgtsrt45thb65675h556543gt46h54n644.mp5"</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_search_engine</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="keyword">return</span> random.sample(search_engine,<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_country</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="keyword">return</span> random.sample(country,<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_level</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="keyword">return</span> random.sample(level,<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_ip</span><span class="params">()</span>:</span></span><br><span class="line">	slice = random.sample(ip_slices , <span class="number">4</span>)</span><br><span class="line">	<span class="keyword">return</span> <span class="string">"."</span>.join([str(item) <span class="keyword">for</span> item <span class="keyword">in</span> slice])</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_domain_name</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="keyword">return</span> random.sample(domain_name,<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_http_referers</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="keyword">if</span> random.uniform(<span class="number">0</span>, <span class="number">1</span>) &gt; <span class="number">0.2</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">"-"</span></span><br><span class="line">		</span><br><span class="line">	ref_str = random.sample(http_referers,<span class="number">1</span>)</span><br><span class="line">	key_str = random.sample(keyword_mp4,<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">return</span> ref_str[<span class="number">0</span>].format(keyword=key_str[<span class="number">0</span>])</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_log</span><span class="params">(count = <span class="number">10</span>)</span>:</span></span><br><span class="line">	time_str = time.strftime(<span class="string">"%d/%b/%Y:%H:%M:%S"</span>, time.localtime())</span><br><span class="line">	</span><br><span class="line">	f = open(<span class="string">"/home/hadoop/data/test.log"</span>,<span class="string">"a+"</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> count &gt;= <span class="number">1</span>:</span><br><span class="line">		query_log = <span class="string">'&#123;se&#125;\t&#123;co&#125;\tA\t&#123;le&#125;\t[&#123;local_time&#125; +0800]\t2\t&#123;ip1&#125;\t-\t&#123;ip2&#125;:80\t0\t&#123;dn&#125;\tGET\t&#123;hr&#125;\tHTTP/1.1	-	bytes 13869056-13885439/25136186	TCP_HIT/206	112.29.213.35	video/mp4	17168\t&#123;num&#125;\t-:0	0	0	-	-	-	11451601	-	"JSP3/2.0.14"	"-"	"-"	"-"	http	-	2	v1.go2yd.com	0.002	25136186	16384	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	1531818470104-11451601-112.29.213.66#2705261172	644514568'</span>.format(se=sample_search_engine(),co=sample_country(),le=sample_level(),local_time=time_str,ip1=sample_ip(),ip2=sample_ip(),dn=sample_domain_name(),hr=sample_http_referers(),num=random.randint(<span class="number">0</span>,<span class="number">999999</span>))</span><br><span class="line">		</span><br><span class="line">		f.write(query_log + <span class="string">"\n"</span>)</span><br><span class="line">		<span class="comment"># print query_log</span></span><br><span class="line">		count=count<span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">	generate_log(<span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<p>生成数据的脚本generate_log.sh<br>[hadoop[@hadoop] data]$ chmod u+x generate_log.sh<br>[hadoop[@hadoop] data]$ ./generate_log.sh<br>generate_log.sh 的内容：【python /home/hadoop/data/generate_log.py】<br>使用tail -f test.log可以查看到有数据产生</p>
<p>利用crontab <a href="https://tool.lu/crontab" target="_blank" rel="noopener">https://tool.lu/crontab</a></p>
<p>crontab.sh脚本；用来定制每个秒级别执行；给这个脚本加上执行权限<br>[hadoop[@hadoop] data]$ chmod u+x crontab.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash  </span></span><br><span class="line">  </span><br><span class="line">step=2 <span class="comment">#间隔的秒数，不能大于60  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> (( i = 0; i &lt; 60; i=(i+step) )); <span class="keyword">do</span>  </span><br><span class="line">    $(sh <span class="string">'/home/hadoop/data/generate_log.sh'</span>)     </span><br><span class="line">    sleep <span class="variable">$step</span>  </span><br><span class="line"><span class="keyword">done</span>  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>


<p>crontab -e进入编辑页面【编辑内容如下】；</p>
<p># crontab -e<br>* * * * * /home/hadoop/data/crontab.sh</p>
<p>使用tail -f test.log可以查看到test.log每2秒钟产生一次数据有数据产生</p>
<p>一条数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">baidu	CN	A	E	[17/Jul/2018:17:07:50 +0800]	2	223.104.18.110	-	112.29.213.35:80	0	v2.go2yd.com	GET	http://v1.go2yd.com/user_upload/1531633977627104fdecdc68fe7a2c4b96b2226fd3f4c.mp4_bd.mp4	HTTP/1.1	-	bytes 13869056-13885439/25136186	TCP_HIT/206	112.29.213.35	video/mp4	17168	16384	-:0	0	0	-	-	-	11451601	-	&quot;JSP3/2.0.14&quot;	&quot;-&quot;	&quot;-&quot;	&quot;-&quot;	http	-	2	v1.go2yd.com	0.002	25136186	16384	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	-	1531818470104-11451601-112.29.213.66#2705261172	644514568</span><br></pre></td></tr></table></figure>

<p>按照tab分割后的字段<br>cdn的厂商，cn中国，A忽略，第四个字段是level: 有E M …. 或者其他的，访问产生的时间，忽略，访问的ip，忽略，服务端的ip，0，域名，url地址，—，TCP_***[关注此字段（这是从cache里拿的）]，17168是所耗费的流量</p>
<h2 id="IDEA创建maven项目-【开始清洗数据】"><a href="#IDEA创建maven项目-【开始清洗数据】" class="headerlink" title="IDEA创建maven项目 【开始清洗数据】"></a>IDEA创建maven项目 【开始清洗数据】</h2><p><img src="1.jpg" alt=""></p>
<p><img src="2.jpg" alt=""></p>
<p>下图注意选择自己的本地maven仓库【要修改为本地自定义repository】<br>$MAVEN_HOME/conf/setting.xml<br><localRepository>D:\\software\\maven_repository</localRepository></p>
<p><img src="3.jpg" alt=""></p>
<p><img src="4.jpg" alt=""></p>
<p><img src="5.jpg" alt=""></p>
<p><img src="6.jpg" alt=""></p>
<h3 id="需要添加hadoop的依赖"><a href="#需要添加hadoop的依赖" class="headerlink" title="需要添加hadoop的依赖"></a>需要添加hadoop的依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.6.0-cdh5.7.0<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">&lt;!--为什么要添加hadoop.version这个变量呢？-方便添加其他Hadoop依赖--&gt;</span> </span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!--添加CDH的仓库--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">&lt;!--添加Hadoop的依赖--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>一定需要和你的这个hadoop版本一致吗？ NO<br>maven工程打包：胖包【jar包和代码全打包】、瘦包 【一般是打成瘦包（只打包自己开发的代码不管jar包）本例子使用瘦包】</p>
<h3 id="解析日志代码"><a href="#解析日志代码" class="headerlink" title="解析日志代码"></a>解析日志代码</h3><h4 id="清洗数据的util"><a href="#清洗数据的util" class="headerlink" title="清洗数据的util"></a>清洗数据的util</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kun.hadoop.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.DateFormat;</span><br><span class="line"><span class="keyword">import</span> java.text.ParseException;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.Locale;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogUtils</span> </span>&#123;</span><br><span class="line">    DateFormat sourceFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"dd/MMM/yyyy:HH:mm:ss"</span>, Locale.ENGLISH);<span class="comment">//源时间</span></span><br><span class="line">    DateFormat targetFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyyMMddHHmmss"</span>);<span class="comment">//转后时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 日志文件解析，对内容进行字段的处理</span></span><br><span class="line"><span class="comment">     * 按\t分割</span></span><br><span class="line"><span class="comment">     * 只抽取我们所需要的字段</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">parse</span><span class="params">(String log)</span> </span>&#123;</span><br><span class="line">        String result = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String[] splits = log.split(<span class="string">"\t"</span>);</span><br><span class="line">            String cdn = splits[<span class="number">0</span>];<span class="comment">//baidu</span></span><br><span class="line">            String region = splits[<span class="number">1</span>];<span class="comment">//CN</span></span><br><span class="line">            String level = splits[<span class="number">3</span>];<span class="comment">//E</span></span><br><span class="line">            String timeStr = splits[<span class="number">4</span>];<span class="comment">//[17/Jul/2018:17:07:50 +0800]</span></span><br><span class="line">            String time = timeStr.substring(<span class="number">1</span>,timeStr.length()-<span class="number">7</span>);</span><br><span class="line">            time = targetFormat.format(sourceFormat.parse(time));</span><br><span class="line">            String ip = splits[<span class="number">6</span>];<span class="comment">//223.104.18.110</span></span><br><span class="line">            String domain = splits[<span class="number">10</span>];<span class="comment">//v2.go2yd.com</span></span><br><span class="line">            String url = splits[<span class="number">12</span>];<span class="comment">//http://v1.go2yd.com/user_upload/1531633977627104fdecdc68fe7a2c4b96b2226fd3f4c.mp4_bd.mp4</span></span><br><span class="line">            String traffic = splits[<span class="number">20</span>];<span class="comment">//17168</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//            System.out.println(cdn);</span></span><br><span class="line"><span class="comment">//            System.out.println(region);</span></span><br><span class="line"><span class="comment">//            System.out.println(level);</span></span><br><span class="line"><span class="comment">//            System.out.println(time);</span></span><br><span class="line"><span class="comment">//            System.out.println(ip);</span></span><br><span class="line"><span class="comment">//            System.out.println(domain);</span></span><br><span class="line"><span class="comment">//            System.out.println(url);</span></span><br><span class="line"><span class="comment">//            System.out.println(traffic);</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">//解析出来的日志 &lt;== external table location是给外部表用的，所以用tab键拼接隔开</span></span><br><span class="line"></span><br><span class="line">            StringBuilder builder = <span class="keyword">new</span> StringBuilder(<span class="string">""</span>);</span><br><span class="line">            builder.append(cdn).append(<span class="string">"\t"</span>)</span><br><span class="line">                    .append(region).append(<span class="string">"\t"</span>)</span><br><span class="line">                    .append(level).append(<span class="string">"\t"</span>)</span><br><span class="line">                    .append(time).append(<span class="string">"\t"</span>)</span><br><span class="line">                    .append(ip).append(<span class="string">"\t"</span>)</span><br><span class="line">                    .append(domain).append(<span class="string">"\t"</span>)</span><br><span class="line">                    .append(url).append(<span class="string">"\t"</span>)</span><br><span class="line">                    .append(traffic);</span><br><span class="line"></span><br><span class="line">            result = builder.toString();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ParseException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="测试上诉util"><a href="#测试上诉util" class="headerlink" title="测试上诉util"></a>测试上诉util</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kun.hadoop;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.kun.hadoop.utils.LogUtils;</span><br><span class="line"><span class="keyword">import</span> org.junit.After;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestLogUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> LogUtils utils ;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLogParse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String log = <span class="string">"baidu\tCN\tA\tE\t[17/Jul/2018:17:07:50 +0800]\t2\t223.104.18.110\t-\t112.29.213.35:80\t0\tv2.go2yd.com\tGET\thttp://v1.go2yd.com/user_upload/1531633977627104fdecdc68fe7a2c4b96b2226fd3f4c.mp4_bd.mp4\tHTTP/1.1\t-\tbytes 13869056-13885439/25136186\tTCP_HIT/206\t112.29.213.35\tvideo/mp4\t17168\t16384\t-:0\t0\t0\t-\t-\t-\t11451601\t-\t\"JSP3/2.0.14\"\t\"-\"\t\"-\"\t\"-\"\thttp\t-\t2\tv1.go2yd.com\t0.002\t25136186\t16384\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t1531818470104-11451601-112.29.213.66#2705261172\t644514568\n"</span>;</span><br><span class="line">        String result = utils.parse(log);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp</span><span class="params">()</span></span>&#123;</span><br><span class="line">        utils = <span class="keyword">new</span> LogUtils();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tearDown</span><span class="params">()</span></span>&#123;</span><br><span class="line">        utils = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">baidu	CN	E	20180717170750	223.104.18.110	v2.go2yd.com	http://v1.go2yd.com/user_upload/1531633977627104fdecdc68fe7a2c4b96b2226fd3f4c.mp4_bd.mp4	16384</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>

<h3 id="开发mapreduce-【这里只有map】"><a href="#开发mapreduce-【这里只有map】" class="headerlink" title="开发mapreduce 【这里只有map】"></a>开发mapreduce 【这里只有map】</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kun.hadoop.mapreduce.mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.kun.hadoop.utils.LogUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogETLMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>,<span class="title">Text</span>,<span class="title">NullWritable</span>,<span class="title">Text</span>&gt;</span>&#123;<span class="comment">//我们要的是value，key没用故用NullWritable</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过mapreduce框架的map方式进行数据清洗</span></span><br><span class="line"><span class="comment">     * 进来一条数据就按照我们的解析规则清洗完以后输出</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> length = value.toString().split(<span class="string">"\t"</span>).length;</span><br><span class="line">        <span class="keyword">if</span>(length == <span class="number">72</span>) &#123;</span><br><span class="line">            LogUtils utils = <span class="keyword">new</span> LogUtils();</span><br><span class="line">            String result = utils.parse(value.toString());</span><br><span class="line">            <span class="keyword">if</span>(StringUtils.isNotBlank(result)) &#123;<span class="comment">//判断是否为空</span></span><br><span class="line">                context.write(NullWritable.get(), <span class="keyword">new</span> Text(result));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="开发一个程序入口"><a href="#开发一个程序入口" class="headerlink" title="开发一个程序入口"></a>开发一个程序入口</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kun.hadoop.mapreduce.driver;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.kun.hadoop.mapreduce.mapper.LogETLMapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.util.SystemClock;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogETLDriver</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"please input 2 params: input output"</span>);</span><br><span class="line">            System.exit(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String input = args[<span class="number">0</span>];</span><br><span class="line">        String output = args[<span class="number">1</span>];  <span class="comment">//output/d=20180717</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//在本地运行的window环境需要加上 而打包到服务器注释掉本行</span></span><br><span class="line">        <span class="comment">// System.setProperty("hadoop.home.dir", "D:\hadoop-common-2.2.0-bin-master");</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断文件系统是否存在，如果存在就删除</span></span><br><span class="line">        FileSystem fileSystem = FileSystem.get(configuration);</span><br><span class="line">        Path outputPath = <span class="keyword">new</span> Path(output);</span><br><span class="line">        <span class="keyword">if</span> (fileSystem.exists(outputPath)) &#123;</span><br><span class="line">            fileSystem.delete(outputPath, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(configuration);</span><br><span class="line">        job.setJarByClass(LogETLDriver<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setMapperClass(LogETLMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setMapOutputKeyClass(NullWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setMapOutputValueClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(input));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(output));</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="本地测试"><a href="#本地测试" class="headerlink" title="本地测试"></a>本地测试</h3><p><img src="7.jpg" alt=""></p>
<p>ipnut 是输入文件的目录；output/d=20180711是输出文件</p>
<p><img src="8.jpg" alt=""></p>
<p>总代码链接</p>
<p><a href="https://gitee.com/li_yu_kun/hadoop_train" target="_blank" rel="noopener">https://gitee.com/li_yu_kun/hadoop_train</a></p>
<p>在本地win运行项目会有坑;所以先准备：<br>1、下载好对应版本的hadoop；配置hadoop对应版本的环境变量即HADOOP_HOME和%HADOOP_HOME/bin【path】<br>2、下载对应的win下运行环境包 <a href="https://github.com/steveloughran/winutils" target="_blank" rel="noopener">https://github.com/steveloughran/winutils</a><br>3、将‘hadoop.dll’和‘winutils.exe’两个文件放入本地%HADOOP_HOME/bin下；同时将hadoop.dll放入C:\Windows\System32文件夹下<br>4、重新运行driver端即可得到结果</p>
<p><img src="9.jpg" alt=""></p>
<h3 id="服务器测试"><a href="#服务器测试" class="headerlink" title="服务器测试"></a>服务器测试</h3><h4 id="项目打包步骤图"><a href="#项目打包步骤图" class="headerlink" title="项目打包步骤图"></a>项目打包步骤图</h4><p><img src="10.jpg" alt=""></p>
<p>打包过程中自动会运行我们自己的单元测试；完成打包后的图示：</p>
<p><img src="11.jpg" alt=""></p>
<p>将jar包上传到hadoop集群服务器上<br><img src="12.jpg" alt=""></p>
<p>运行方式为</p>
<p>hadoop jar 服务器上的jar包位置 主类【见下图】 入参【日志文件路径】 出参【日志文件夹路径】</p>
<p><img src="13.jpg" alt=""></p>
<p>将日志文件上传到hdfs集群</p>
<p>[hadoop[@hadoop] data]$ hadoop fs -mkdir /input<br>[hadoop[@hadoop] data]$ hadoop fs -put test.log /input<br>[hadoop[@hadoop] data]$ hadoop fs -ls /input<br>Found 1 items<br>-rw-r–r–   1 hadoop supergroup     379093 2019-03-29 11:36 /input/test.log<br>[hadoop[@hadoop] data]$ </p>
<p>运行hadoop jar /home/hadoop/data/hadoop_train-1.0-SNAPSHOT.jar com.kun.hadoop.mapreduce.driver.LogETLDriver /input /home/hadoop/data/output 得出下图结果</p>
<p><a href="http://192.168.232.8:8088/" target="_blank" rel="noopener">http://192.168.232.8:8088</a><br><img src="14.jpg" alt=""><br><a href="http://192.168.232.8:50070/" target="_blank" rel="noopener">http://192.168.232.8:50070</a><br><img src="15.jpg" alt=""></p>
<p>创建运行本作业的shell脚本【hadoop-train.sh 具体内容在代码框里】</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">process_data=20180717</span><br><span class="line"></span><br><span class="line">echo &quot;step1:mapreduce etl&quot;</span><br><span class="line">#安装常理输出到分区里；输出参数加上day=20180717</span><br><span class="line">hadoop jar /home/hadoop/data/hadoop_train-1.0-SNAPSHOT.jar com.kun.hadoop.mapreduce.driver.LogETLDriver /input /home/hadoop/data/output/day=$process_data</span><br></pre></td></tr></table></figure>

<p>[hadoop@hadoop data]$ vim hadoop-train.sh<br>[hadoop@hadoop data]$ chmod u+x hadoop-train.sh<br>[hadoop@hadoop data]$ ./hadoop-train.sh 【运行脚本】</p>
<p>[hadoop@hadoop data]$ hadoop dfs -ls /home/hadoop/data/</p>
<p>Found 1 items<br>drwxr-xr-x   - hadoop supergroup          0 2019-03-29 12:20 /home/hadoop/data/output<br>[hadoop@hadoop data]$ hadoop dfs -ls /home/hadoop/data/output</p>
<p>Found 3 items<br>-rw-r–r–   1 hadoop supergroup          0 2019-03-29 11:38 /home/hadoop/data/output/_SUCCESS<br>drwxr-xr-x   - hadoop supergroup          0 2019-03-29 12:21 /home/hadoop/data/output/day=20180717<br>-rw-r–r–   1 hadoop supergroup      72432 2019-03-29 11:38 /home/hadoop/data/output/part-r-00000<br>[hadoop@hadoop data]$ hadoop dfs -ls /home/hadoop/data/output/day=20180717</p>
<p>Found 2 items<br>-rw-r–r–   1 hadoop supergroup          0 2019-03-29 12:21 /home/hadoop/data/output/day=20180717/_SUCCESS<br>-rw-r–r–   1 hadoop supergroup      72432 2019-03-29 12:21 /home/hadoop/data/output/day=20180717/part-r-00000</p>
<h1 id="Hive完成最基本的统计分析"><a href="#Hive完成最基本的统计分析" class="headerlink" title="Hive完成最基本的统计分析"></a>Hive完成最基本的统计分析</h1><p>mapreduce作业不用指定内存，是指定不了的</p>
<h2 id="创建外部表"><a href="#创建外部表" class="headerlink" title="创建外部表"></a>创建外部表</h2><p>location指定的不是mapreduce作业的输出路径 why？因为会覆盖掉</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> hadoop_access (</span><br><span class="line">cdn <span class="keyword">string</span>,</span><br><span class="line">region <span class="keyword">string</span>,</span><br><span class="line"><span class="keyword">level</span> <span class="keyword">string</span>,</span><br><span class="line"><span class="built_in">time</span> <span class="keyword">string</span>,</span><br><span class="line">ip <span class="keyword">string</span>,</span><br><span class="line"><span class="keyword">domain</span> <span class="keyword">string</span>,</span><br><span class="line"><span class="keyword">url</span> <span class="keyword">string</span>,</span><br><span class="line">traffic <span class="built_in">bigint</span></span><br><span class="line">) partitioned <span class="keyword">by</span> (<span class="keyword">day</span> <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span></span><br><span class="line">LOCATION <span class="string">'/home/hadoop/data/clear'</span></span><br></pre></td></tr></table></figure>

<h2 id="启动hive"><a href="#启动hive" class="headerlink" title="启动hive"></a>启动hive</h2><p><img src="16.jpg" alt=""><br><img src="17.jpg" alt=""></p>
<h2 id="移动数据到外部表对应的目录"><a href="#移动数据到外部表对应的目录" class="headerlink" title="移动数据到外部表对应的目录"></a>移动数据到外部表对应的目录</h2><p>[hadoop@hadoop data]$ hadoop fs -ls /home/hadoop/data/clear<br>ls: `/home/hadoop/clear’: No such file or directory<br>[hadoop@hadoop data]$ hadoop fs -mkdir /home/hadoop/data/clear<br>[hadoop@hadoop data]$ hadoop fs -ls /home/hadoop/data/clear<br>[hadoop@hadoop data]$ hadoop fs -mkdir -p /home/hadoop/data/clear/day=20180717<br>[hadoop@hadoop data]$ hadoop fs -mv /home/hadoop/data/output/day=20180717/part-r-00000 /home/hadoop/data/clear/day=20180717<br>[hadoop@hadoop data]$ hadoop fs -ls /home/hadoop/data/clear/day=20180717<br>Found 1 items<br>-rw-r–r–   1 hadoop supergroup      72432 2019-03-29 12:21 /home/hadoop/data/clear/day=20180717/part-r-00000<br>[hadoop@hadoop data]$</p>
<h2 id="刷元数据到hive中"><a href="#刷元数据到hive中" class="headerlink" title="刷元数据到hive中"></a>刷元数据到hive中</h2><p><img src="18.jpg" alt=""></p>
<h2 id="统计每个域名的traffic之和"><a href="#统计每个域名的traffic之和" class="headerlink" title="统计每个域名的traffic之和"></a>统计每个域名的traffic之和</h2><p><img src="19.jpg" alt=""></p>
<p>补全hadoop-train.sh脚本 然后执行【./hadoop-train.sh】</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">process_data=20180717</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"step1:mapreduce etl"</span></span><br><span class="line"><span class="comment">#安装常理输出到分区里；输出参数加上day=20180717</span></span><br><span class="line">hadoop jar /home/hadoop/data/hadoop_train-1.0-SNAPSHOT.jar com.kun.hadoop.mapreduce.driver.LogETLDriver /input /home/hadoop/data/output/day=<span class="variable">$process_data</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"step2:hdfsdata mv hive"</span></span><br><span class="line">hadoop fs -rmr /home/hadoop/data/clear/day=<span class="variable">$process_data</span></span><br><span class="line">hadoop fs -mkdir -p /home/hadoop/data/clear/day=<span class="variable">$process_data</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"step3:Brush the metadata"</span></span><br><span class="line">hive -e <span class="string">"alter table hadoop_access add if not exists partition(day=<span class="variable">$process_data</span>)"</span></span><br></pre></td></tr></table></figure>

<p><img src="20.jpg" alt=""></p>
<p><img src="21.jpg" alt=""></p>
<p>优化：建议：创建一张parquet，然后修改shell就搞定了</p>
<p>创建一个新表，parquet表</p>
<p>可以在做查询操作之前将hadoop_access 表的数据insert到新表parquet中；删除原表；这样对存储和以后的查询操作都有性能提升<br>traffic统计    text  vs  parquet  对比结果</p>

                

                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/article/[Sqoop] Sqoop入门/" data-toggle="tooltip" data-placement="top" title="[Sqoop] Sqoop入门">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/article/[Hadoop]23 Hadoop离线项目整体技术/" data-toggle="tooltip" data-placement="top" title="[Hadoop]23 Hadoop离线项目整体技术">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                <br>

                <!--打赏-->
                
                <!--打赏-->

                <br>
                <!--分享-->
                
                    <div class="social-share"  data-wechat-qrcode-helper="" align="center"></div>
                    <!--  css & js -->
                    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
                    <script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
                
                <!--分享-->
                <br>                       
                
                <!-- require APlayer -->
                

                <!-- duoshuo Share start -->
                
                <!-- 多说 Share end-->

                <!-- 多说评论框 start -->
                
                <!-- 多说评论框 end -->

                <!-- disqus comment start -->
                
                <!-- disqus comment end -->

                

            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

  
    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#企业级大数据应用分类"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">企业级大数据应用分类</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#基于Maven构建大数据开发项目"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">基于Maven构建大数据开发项目</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#手动造数据"><span class="toc-nav-number">2.1.</span> <span class="toc-nav-text">手动造数据</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#IDEA创建maven项目-【开始清洗数据】"><span class="toc-nav-number">2.2.</span> <span class="toc-nav-text">IDEA创建maven项目 【开始清洗数据】</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#需要添加hadoop的依赖"><span class="toc-nav-number">2.2.1.</span> <span class="toc-nav-text">需要添加hadoop的依赖</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#解析日志代码"><span class="toc-nav-number">2.2.2.</span> <span class="toc-nav-text">解析日志代码</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#清洗数据的util"><span class="toc-nav-number">2.2.2.1.</span> <span class="toc-nav-text">清洗数据的util</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#测试上诉util"><span class="toc-nav-number">2.2.2.2.</span> <span class="toc-nav-text">测试上诉util</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#测试结果"><span class="toc-nav-number">2.2.2.3.</span> <span class="toc-nav-text">测试结果</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#开发mapreduce-【这里只有map】"><span class="toc-nav-number">2.2.3.</span> <span class="toc-nav-text">开发mapreduce 【这里只有map】</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#开发一个程序入口"><span class="toc-nav-number">2.2.4.</span> <span class="toc-nav-text">开发一个程序入口</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#本地测试"><span class="toc-nav-number">2.2.5.</span> <span class="toc-nav-text">本地测试</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#服务器测试"><span class="toc-nav-number">2.2.6.</span> <span class="toc-nav-text">服务器测试</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#项目打包步骤图"><span class="toc-nav-number">2.2.6.1.</span> <span class="toc-nav-text">项目打包步骤图</span></a></li></ol></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#Hive完成最基本的统计分析"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">Hive完成最基本的统计分析</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#创建外部表"><span class="toc-nav-number">3.1.</span> <span class="toc-nav-text">创建外部表</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#启动hive"><span class="toc-nav-number">3.2.</span> <span class="toc-nav-text">启动hive</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#移动数据到外部表对应的目录"><span class="toc-nav-number">3.3.</span> <span class="toc-nav-text">移动数据到外部表对应的目录</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#刷元数据到hive中"><span class="toc-nav-number">3.4.</span> <span class="toc-nav-text">刷元数据到hive中</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#统计每个域名的traffic之和"><span class="toc-nav-number">3.5.</span> <span class="toc-nav-text">统计每个域名的traffic之和</span></a></li></ol></li></ol>
        
        </div>
      </aside>
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#Hadoop" title="Hadoop">Hadoop</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
            </div>
        </div>
    </div>
</article>








<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


<!-- chrome Firefox 中文锚点定位失效-->
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
<!-- smooth scroll behavior polyfill  -->
<script type="text/javascript" src="/js/smoothscroll.js"></script>
<script>
        $('#toc').on('click','a',function(a){
            // var isChrome = window.navigator.userAgent.indexOf("Chrome") !== -1;
            // console.log(window.navigator.userAgent,isChrome)
                // if(isChrome) {
                    // console.log(a.currentTarget.outerHTML);
                    // console.log($(a.currentTarget).attr("href"));
                    //跳转到指定锚点
                    // document.getElementById(a.target.innerText.toLowerCase()).scrollIntoView(true);
                    document.getElementById($(a.currentTarget).attr("href").replace("#","")).scrollIntoView({behavior: 'smooth' });
                // }
        })  
</script>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                

                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/li-yu-kun">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; 李玉坤 2020 
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span> 
                    By <a href="https://li-yu-kun.github.io/">李玉坤</a> | 
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=li-yu-kun&repo=li-yu-kun.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://li-yu-kun.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-XXXXXXXX-X';
    var _gaDomain = 'yoursite';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->

<script>
    // dynamic User by Hux
    var _baId = 'xxx';

    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>





	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>
<!-- Image to hack wechat -->
<img src="https://li-yu-kun.github.io/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
